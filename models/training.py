import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from db.data import get_dataset_entrenamiento
from utils.preprocessing import preparar_dataset_entrenamiento
import joblib

# Importar los modelos de Scikit-learn
from sklearn.ensemble import RandomForestClassifier # Para Random Forest
from sklearn.neighbors import KNeighborsClassifier # Para K-Nearest Neighbors (opcional)
from sklearn.metrics import classification_report, accuracy_score

def train_and_save_model():
    """
    Obtiene los datos, los preprocesa, entrena un modelo de clasificaci√≥n
    (Random Forest por defecto), lo eval√∫a y lo guarda junto con el preprocesador
    y el LabelEncoder.
    """
    print("üîÑ Obteniendo datos de la base de datos...")
    datos = get_dataset_entrenamiento()
    if not datos:
        print("‚ùå No hay datos para entrenar. Aseg√∫rate de que la base de datos no est√© vac√≠a.")
        return

    print("üìä Preprocesando datos...")
    # Desempaquetar correctamente la salida de la funci√≥n preparar_dataset_entrenamiento
    (X_train, X_test, y_train, y_test), preprocessor, label_encoder_y = preparar_dataset_entrenamiento(datos)

    print(f"Dimensiones de X_train: {X_train.shape}")
    print(f"Dimensiones de y_train: {y_train.shape}")
    print(f"Dimensiones de X_test: {X_test.shape}")
    print(f"Dimensiones de y_test: {y_test.shape}")


    # --- Selecci√≥n y Entrenamiento del Modelo ---

    # Opci√≥n 1: Random Forest Classifier (Recomendado)
    print("üß† Entrenando modelo Random Forest Classifier...")
    # n_estimators: n√∫mero de √°rboles en el bosque
    # random_state: para reproducibilidad de resultados
    # class_weight: √∫til si tus clases (dep√≥sitos) est√°n desbalanceadas
    model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')
    model.fit(X_train, y_train)
    print("‚úÖ Entrenamiento de Random Forest completado.")

    # Opci√≥n 2: K-Nearest Neighbors Classifier (Descomentar para usar)
    # print("üß† Entrenando modelo K-Nearest Neighbors Classifier...")
    # model = KNeighborsClassifier(n_neighbors=5) # n_neighbors: n√∫mero de vecinos a considerar
    # model.fit(X_train, y_train)
    # print("‚úÖ Entrenamiento de K-NN completado.")


    # --- Evaluaci√≥n del Modelo ---
    print("üìà Evaluando el modelo en el conjunto de prueba...")
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"üéØ Accuracy en el conjunto de prueba: {accuracy:.4f}")

    # Mostrar reporte de clasificaci√≥n para una evaluaci√≥n m√°s detallada
    # Reconvertimos las etiquetas num√©ricas a los nombres originales para el reporte
    y_test_original = label_encoder_y.inverse_transform(y_test)
    y_pred_original = label_encoder_y.inverse_transform(y_pred)

    print("\n--- Reporte de Clasificaci√≥n ---")
    print(classification_report(y_test_original, y_pred_original))


    # --- Guardado del Modelo y Componentes de Preprocesamiento ---
    save_dir = Path("models/saved")
    save_dir.mkdir(parents=True, exist_ok=True)

    # Guardar el modelo entrenado
    model_path = save_dir / "modelo_deposito.joblib"
    joblib.dump(model, model_path)
    print(f"‚úÖ Modelo guardado en: {model_path}")

    # Guardar el preprocesador (ColumnTransformer)
    preprocessor_path = save_dir / "preprocessor.joblib"
    joblib.dump(preprocessor, preprocessor_path)
    print(f"‚úÖ Preprocesador guardado en: {preprocessor_path}")

    # Guardar el LabelEncoder de la variable objetivo (y)
    label_encoder_y_path = save_dir / "label_encoder_y.joblib"
    joblib.dump(label_encoder_y, label_encoder_y_path)
    print(f"‚úÖ LabelEncoder para 'y' guardado en: {label_encoder_y_path}")

    print("\nüì¶ Todos los componentes del modelo (modelo, preprocesador, LabelEncoder) han sido guardados.")

    # --- Visualizaci√≥n (Adaptada para modelos de Scikit-learn) ---
    # Los modelos de Scikit-learn no tienen un "history" como Keras para graficar
    # la p√©rdida y la precisi√≥n por √©poca. Sin embargo, podemos mostrar m√©tricas
    # importantes como la importancia de las caracter√≠sticas para Random Forest.

    if isinstance(model, RandomForestClassifier):
        print("\n--- Importancia de las Caracter√≠sticas (Random Forest) ---")
        # Asegurarse de que X_train_df tiene los nombres de las columnas correctos
        # X_train es un DataFrame con los nombres de columnas correctos del preprocesamiento
        feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)
        feature_importances.nlargest(10).plot(kind='barh')
        plt.title('Importancia de las Caracter√≠sticas')
        plt.xlabel('Importancia Relativa')
        plt.ylabel('Caracter√≠stica')
        plt.tight_layout()
        plt.show()
    else:
        print("\nNota: La visualizaci√≥n de la historia de entrenamiento no es aplicable directamente a K-NN.")
        print("Para Random Forest, se puede visualizar la importancia de las caracter√≠sticas.")


if __name__ == "__main__":
    train_and_save_model()